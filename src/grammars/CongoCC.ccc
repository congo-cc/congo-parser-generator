ENSURE_FINAL_EOL;
JAVA_UNICODE_ESCAPE;
PARSER_PACKAGE=org.congocc.parser;
NODE_PACKAGE=org.congocc.parser.tree;
DEFAULT_LEXICAL_STATE=JAVA;
BASE_SRC_DIR="../../build/generated-java";

USES_PREPROCESSOR;

DEACTIVATE_TOKENS=_INCLUDE,_INJECT,_EOF, RECORD, VAR, YIELD, SEALED, NON_SEALED, PERMITS;


/* congocc RESERVED WORDS: These are the only tokens in congocc but not in Java */

TOKEN :
  < _INJECT: "INJECT" > #CongoCCKeyWord
  |
  < _INCLUDE : "INCLUDE" | "INCLUDE_GRAMMAR"> #CongoCCKeyWord
  |
  < _FAIL : "FAIL" > #CongoCCKeyWord
  |
  < _UNCACHE_TOKENS : "UNCACHE_TOKENS"> #CongoCCKeyWord
  |
  < _ACTIVE_TOKENS : "ACTIVE_TOKENS"> #CongoCCKeyWord
  |
  < _ACTIVATE_TOKENS : "ACTIVATE_TOKENS"> #CongoCCKeyWord
  |
  < _DEACTIVATE_TOKENS : "DEACTIVATE_TOKENS"> #CongoCCKeyWord  
  |
  < _ENSURE : "ASSERT"> #CongoCCKeyWord
  |
  < _SCAN : "SCAN" > #CongoCCKeyWord
  |
  < _IGNORE_CASE: "IGNORE_CASE" > #CongoCCKeyWord
  |
  < _TOKEN: "TOKEN" | "REGULAR_TOKEN"> #CongoCCKeyWord
  |
  < _CONTEXTUAL_KEYWORD: "CONTEXTUAL_KEYWORD" > #CongoCCKeyWord
  |
  < _UNPARSED: "SPECIAL_TOKEN" | "UNPARSED" > #CongoCCKeyWord
  |
  < _MORE: "MORE" | "INCOMPLETE_TOKEN" > #CongoCCKeyWord
  |
  < _SKIP: "SKIP" > #CongoCCKeyWord
  |
  < _EOF : "EOF"> #CongoCCKeyWord
  |
  < _ATTEMPT: "ATTEMPT"> #CongoCCKeyWord
  |
  < _RECOVER : "RECOVER"> #CongoCCKeyWord
  |
  < _RECOVER_TO : "RECOVER_TO"> #CongoCCKeyWord
  |
  < _ON_ERROR : "ON_ERROR"> #CongoCCKeyWord
  |
  <HASH : "#">
  |
  <BACKSLASH : "\\"> #Backslash
  |
  <RIGHT_ARROW : "=>"> #RightArrow
  |
  <UP_TO_HERE : "=>|" ("|" | ("+" ["0"-"9"]))> 
  |
  <_LEXICAL_STATE : "LEXICAL_STATE"> #CongoCCKeyWord
  |
  <SINGLE_QUOTE_STRING:
      "'"
      (
          ~["'","\\","\n","\r"]
          |
          <STRING_ESCAPE>
      ){2,}
       "'"
  > #StringLiteral
  |
  <START_UNPARSED : "{$" >
;

INCLUDE "Lexical.inc.ccc"
INCLUDE "JavaInternal.ccc"

INJECT LEXER_CLASS : 
{
  // Set whether to generate unparsed tokens for WHITESPACE
  static public void keepWhitespace(boolean b) {
    if (b) {
        skippedTokens.remove(WHITESPACE);
        unparsedTokens.add(WHITESPACE);
    } else {
        skippedTokens.add(WHITESPACE);
        unparsedTokens.remove(WHITESPACE);
    }
  }
}

INJECT PARSER_CLASS :
    import java.util.*;
    import org.congocc.app.*;
    import org.congocc.core.*;
    import org.congocc.parser.tree.StringLiteral;
    import org.congocc.parser.tree.IntegerLiteral;
    import org.congocc.preprocessor.PreprocessorParser;
    import org.congocc.parser.csharp.CSParser;
    import org.congocc.parser.python.PythonParser;
    import org.congocc.parser.python.ast.Module;
{
    Grammar grammar;

    void OPEN_NODE_HOOK(Node n) {
        n.setGrammar(grammar);
    }
    
    public PARSER_CLASS(Grammar grammar, Path path, Map<String, String> definedSymbols) throws IOException{
        this(path.toString(), path);
        this.grammar = grammar;
        BitSet lineMarkers = null;
        PreprocessorParser ppp = new PreprocessorParser(path, definedSymbols);
        lineMarkers = ppp.PP_Root();
        token_source.setParsedLines(lineMarkers);
    }

    public PARSER_CLASS(Grammar grammar, String inputSource, CharSequence content) {
         this(inputSource, content);
         this.grammar = grammar;
         BitSet lineMarkers = null;
         lineMarkers = new PreprocessorParser(content).PP_Root();
         token_source.setParsedLines(lineMarkers);
    }
    
    static public CompilationUnit parseJavaFile(String inputSource, CharSequence content) {
        PARSER_CLASS parser = new PARSER_CLASS(inputSource, content);
        return parser.CompilationUnit();
    }

    static public CompilationUnit parseJavaFile(Path path) throws IOException {
        PARSER_CLASS parser = new PARSER_CLASS(path);
        return parser.CompilationUnit();
    }

    static public Module parsePythonFile(String inputSource, CharSequence content, boolean useAltIndentDedent) {
        PythonParser parser = new PythonParser(inputSource, content);
//        parser.setUseAltIndentDedent(useAltIndentDedent);
        return parser.Module();
    }

    static public Module parsePythonFile(Path path, boolean useAltIndentDedent) throws IOException {
        PythonParser parser = new PythonParser(path);
//        parser.setUseAltIndentDedent(useAltIndentDedent);
        return parser.Module();
    }
    
    static public org.congocc.parser.csharp.ast.CompilationUnit parseCSharpFile(String inputSource, CharSequence content) {
        CSParser parser  = new CSParser(inputSource, content);
        return parser.CompilationUnit();
    } 

    static public org.congocc.parser.csharp.ast.CompilationUnit parseCSharpFile(Path path) throws IOException {
        CSParser parser  = new CSParser(path);
        return parser.CompilationUnit();
    } 

    public Grammar getGrammar() {
        return grammar;
    }

    public AppSettings getAppSettings() {
        return grammar.getAppSettings();
    }

    public Errors getErrors() {
        return grammar.getErrors();
    }
    
    public void openNodeScopeHook(Node n) {
        n.setGrammar(grammar);
    }

}

<IN_UNPARSED_CODE_BLOCK> TOKEN : 
  <UNPARSED_CONTENT : (~["$"] | (("$")+ ~["}"]))+ > #UnparsedContent
  |
  <END_UNPARSED : "$}" >
;

UnparsedCodeBlock #org.congocc.core.UnparsedCodeBlock : 
   <START_UNPARSED> 
   LEXICAL_STATE IN_UNPARSED_CODE_BLOCK
   (
     [<UNPARSED_CONTENT>]
     <END_UNPARSED>
   )
;

INJECT Node : @SuppressWarnings("unused")
//INJECT Node : @freemarker.annotations.Pojo 

INJECT BASE_NODE_CLASS :
    import org.congocc.app.*;
    import org.congocc.core.Grammar;
    import PARSER_PACKAGE.Token.TokenType;
    @SuppressWarnings("unused")
    implements Node; 
{
    protected void setChildren(List<Node> children) {
        this.children = children;
    }

    Grammar grammar;

    public Grammar getGrammar() {
        if (grammar == null) { // temporary kludge
            BASE_NODE_CLASS parent = (BASE_NODE_CLASS) getParent();
            while (grammar == null && parent != null) {
                grammar = ((BaseNode)getParent()).grammar;
                if (grammar != null) break;
                parent = (BASE_NODE_CLASS) getParent();
            }
        }
        return grammar;
    }

    public void setGrammar(Grammar grammar) {
        this.grammar = grammar;
    }

    public AppSettings getAppSettings() {
        return getGrammar().getAppSettings();
    }

    public Errors getErrors() {
        return getGrammar().getErrors();
    }
    
    public String getSimpleName() {
        String name = getClass().getName();
        return name.substring(name.lastIndexOf(".") + 1); // strip the package name
    }

    public String toString() {
        StringBuilder buf = new StringBuilder();
        TerminalNode prevToken = null;
        for (TerminalNode t : getAllTokens(true)) {
            if (prevToken != null && prevToken.getEndOffset() != t.getBeginOffset()) {
                buf.append(" ");
            }
            buf.append(t);
            prevToken = t;
        }
        return buf.toString();
    }

    public String getInputSource() {
        return getTokenSource().getInputSource();
    }

    public String getLocation() {
        return getInputSource() + ":" + getBeginLine() + ":" + getBeginColumn();
    }

    public int getBeginLine() {
        TokenSource tokenSource = getTokenSource();
        return tokenSource == null ? 0 : tokenSource.getLineFromOffset(getBeginOffset());
    }

    public int getBeginColumn() {
        TokenSource tokenSource = getTokenSource();
        return tokenSource == null ? 0 : tokenSource.getCodePointColumnFromOffset(getBeginOffset());
    }
}

INJECT CodeBlock :
  import java.util.List;
   extends org.congocc.core.EmptyExpansion;
{
    @Property boolean appliesInLookahead;

    public CodeBlock getJavaCode() {
        return this;
    }

    @Override 
    public boolean startsWithGlobalCodeAction() {
        return isAppliesInLookahead();
    }

    public String toString() {
        StringBuilder buf = new StringBuilder();
        List<? extends TerminalNode> tokens = getAllTokens(true);
        boolean outputOpeningBrace = false;
        for (int i=0; i<tokens.size() -1; i++) {
            Token t = (Token) tokens.get(i);
            buf.append(" ");
            if (i>0 && ((Token)tokens.get(i-1)).getEndOffset() != t.getBeginOffset()) {
                buf.append(" ");
            }
            if (outputOpeningBrace) {
                buf.append(t);
            } else if (t.getType() == TokenType.LBRACE) {
                outputOpeningBrace = true;
            }
            buf.append(" ");
        }
        return buf.toString();
    }
}



INJECT PARSER_CLASS : {

    private EnumSet<TokenType> CongoCCKeyWords = EnumSet.of(
       _FAIL, _ENSURE, _SCAN, _IGNORE_CASE, 
       _TOKEN, _CONTEXTUAL_KEYWORD, _UNPARSED, _SKIP, _MORE,
       _ATTEMPT, _RECOVER, _ON_ERROR,  
       _LEXICAL_STATE);

    private Token TOKEN_HOOK(Token t) {
        if (CongoCCKeyWords.contains(t.getType())) {
            if (isInProduction("CompilationUnit", "ClassOrInterfaceBody", "BlockStatement", "TreeBuildingAnnotation")) {
                Token id = Token.newToken(IDENTIFIER, t.toString(), token_source);
                id.copyLocationInfo(t);
                return id;
            }
        }
        t.setGrammar(getGrammar());
        return t;
    }
}


INJECT Identifier : 
{
    public String toString() {
        String cachedImage = getCachedImage();
        if (cachedImage != null) return cachedImage;
        String image = getSource();
        if (image.equals("jjtThis") || image.equals("CURRENT_NODE")) { 
            image = getGrammar().getTemplateGlobals().getCurrentNodeVariableName();
        }
        else if (image.equals("PARSER_CLASS")) {
            image = getAppSettings().getParserClassName();
        }
        else if (image.equals("LEXER_CLASS")) {
            image = getAppSettings().getLexerClassName();
        }
        else if (image.equals("BASE_NODE_CLASS")) {
            image = getAppSettings().getBaseNodeClassName();
        }
        else if (image.equals("BASE_TOKEN_CLASS")) {
            image = getAppSettings().getBaseTokenClassName();
        }
        else if (image.equals("NODE_PACKAGE")) {
            image =  getAppSettings().getNodePackage();
        }
        else if (image.equals("PARSER_PACKAGE")) {
            image = getAppSettings().getParserPackage();
        }
        else if (image.equals("TOKEN_HOOK")) {
            String prefix = getAppSettings().generateIdentifierPrefix("tokenHook");
            image = getAppSettings().generateUniqueIdentifier(prefix, this);
            setCachedImage(image);
        }
        else if (image.equals("RESET_TOKEN_HOOK")) {
            String prefix = getAppSettings().generateIdentifierPrefix("resetTokenHook");
            image = getAppSettings().generateUniqueIdentifier(prefix, this);
            setCachedImage(image);
        }
        else if (image.equals("OPEN_NODE_HOOK")) {
            String prefix = getAppSettings().generateIdentifierPrefix("openNodeHook");
            image = getAppSettings().generateUniqueIdentifier(prefix, this);
            setCachedImage(image);
        }
        else if (image.equals("CLOSE_NODE_HOOK")) {
            String prefix = getAppSettings().generateIdentifierPrefix("closeNodeHook");
            image = getAppSettings().generateUniqueIdentifier(prefix, this);
            setCachedImage(image);
        }
        assert image != null;
        return image;
   }
}

INJECT interface Node :
   import org.congocc.core.Grammar;
{
    Grammar getGrammar();
    void setGrammar(Grammar grammar);
    default Node getNamedChild(String name) { return null; }
    default void setNamedChild(String name, Node node) {}
    default  List<Node> getNamedChildList(String name) { return null; }
    default void addToNamedChildList(String name, Node node) {}
}


INJECT Token :
    import org.congocc.app.AppSettings;
    import org.congocc.app.Errors;
    import org.congocc.core.Grammar;
{
    private Grammar grammar;

    public Grammar getGrammar() {
        if (grammar == null) {
           if (parent != null) {
              grammar = parent.getGrammar();
           }
        }
        return grammar;
    }

    public void setGrammar(Grammar grammar) {
         this.grammar = grammar;
    }

    public AppSettings getAppSettings() {
        return getGrammar().getAppSettings();
    }

    public Errors getErrors() {
        return getGrammar().getErrors();
    }
    
    public String getNodeName() {
        return getType().toString();
    }
    
    public String getLeadingComments() {
        Token specialToken = getPreviousToken() == null || !getPreviousToken().isUnparsed() ? null : getPreviousToken();
        if (specialToken == null)
            return "";
        StringBuilder buf = new StringBuilder();
        Token tok = specialToken;
        while (tok.getPreviousToken() != null && tok.getPreviousToken().isUnparsed()) {
            tok = tok.getPreviousToken();
        }
        while (tok != this && tok != null) {
            buf.append(tok);
            tok = tok.getNext();
        }
        return buf.toString();
    }
}    

#Root throws IOException #GrammarFile :
{
    TokenProduction tp;
}
   [
      Options
   ]!
   (
      tp=TokenProduction 
      |
      CodeInjection2 
      |
      CodeInjection
      |
      GrammarInclusion =>||
      |
      BNFProduction
  )+!
  <EOF>
  {
        return CURRENT_NODE;
  }
;

INJECT GrammarFile :
{
    @Property String defaultLexicalState;
}

INJECT ReturnType :
    import java.util.List;
{
    public boolean getAsBoolean() {
        List<Token> lt = getRealTokens();
        return lt.size() != 1 || lt.get(0).getType() != VOID;
    }
}

INJECT PARSER_CLASS : {
    private boolean enterIncludes = true, isAlias = false;
    public void setEnterIncludes(boolean enterIncludes) {this.enterIncludes = enterIncludes;}
}

GrammarInclusion throws IOException :
{
   List<String> locations = new ArrayList<>();
   Token includeToken;
}
   ACTIVATE_TOKENS _INCLUDE (<_INCLUDE>)
   {includeToken = lastConsumedToken;}
   (
       (
           <STRING_LITERAL> {locations.add(((StringLiteral)lastConsumedToken).getString());}
           |
           <IDENTIFIER> {locations.add(lastConsumedToken.toString());}
       )
       (
         "!" 
         (<STRING_LITERAL>|<IDENTIFIER>)
         {
           if (lastConsumedToken instanceof StringLiteral) {
              locations.add(((StringLiteral) lastConsumedToken).getString());
           } else {
               locations.add(lastConsumedToken.toString());
           }
         }
       )*
       |
       "(" <STRING_LITERAL> {locations.add(((StringLiteral)lastConsumedToken).getString());} ")" 
   )
   [";"]
   {
      if (enterIncludes) {
          Node included = grammar.include(locations, includeToken);
          if (included!=null) {
              CURRENT_NODE.addChild(included);
          } else {
              getErrors().addWarning(CURRENT_NODE, "File is already included.");
          }
      }
   }
;

#CodeInjection :
{
    boolean isInterface = false;
    boolean isSealed=false;
    boolean foundOptionalInitialBrace = false;
    boolean usingParentheses = false;
    ObjectType ot;
    ClassOrInterfaceBody coib;
}   
        ACTIVATE_TOKENS _INJECT (<_INJECT>) 
        {permissibleModifiers = EnumSet.of(ABSTRACT,FINAL,STRICTFP,SEALED,NON_SEALED);}
        Modifiers
        {isSealed = peekNode().getType()==SEALED || peekNode().firstChildOfType(SEALED)!=null;}
        [
            "class"
            |
            "interface" {isInterface = true;}
        ]
        <IDENTIFIER> {CURRENT_NODE.setName(lastConsumedToken.toString());}
        ":"
        =>|+1
        [
          SCAN "{" ("}" | "import" | "extends" | "implements" | (Annotation)* "}") => "{"
          {foundOptionalInitialBrace=true;}
        ]
        (ImportDeclaration)*
        (Annotation)*
        [
             "extends" 
             ot=ObjectType {CURRENT_NODE.addExtendsType(ot);}
             (SCAN 1 {isInterface} => "," ot=ObjectType {CURRENT_NODE.addExtendsType(ot);})*
             [";"]
        ]
        [
             SCAN 1 {!isInterface} =>
             "implements" ot=ObjectType {CURRENT_NODE.addImplementsType(ot);}
             ("," ot=ObjectType {CURRENT_NODE.addImplementsType(ot);})*
             [";"]
        ]
        ASSERT {!isSealed || checkNextTokenImage("permits")} : "Expecting 'permits' here" :
        [PermitsList [";"]]
        [
           SCAN 0 {foundOptionalInitialBrace} => "}"
        ]
        [coib=ClassOrInterfaceBody {CURRENT_NODE.body = coib;}]
        {
                if (enterIncludes) {
                    grammar.addCodeInjection(CURRENT_NODE);
                }
                return CURRENT_NODE;
        }
;

INJECT CodeInjection : 
   import java.util.List;
   import java.util.ArrayList;
#if __java__
   import org.congocc.core.Grammar;
#endif
{
   public List<ObjectType> extendsList = new ArrayList<>();
   public List<ObjectType> implementsList = new ArrayList<>();
   public ClassOrInterfaceBody body;
#if __java__
   public static void inject(Grammar grammar, String nodeName, String injection) {
        String inject = "INJECT " + nodeName + " : " + injection;
        CongoCCParser parser;
        try {
            parser = new CongoCCParser(grammar, "dynamicInjection", inject);
            parser.setEnterIncludes(true);
            CodeInjection ci = parser.CodeInjection();
            grammar.getInjector().add(ci);
        } catch (Exception e) {
            //FIXME: need something better here!
            System.err.println("parser exception: " + e.getLocalizedMessage());
        } finally {
            parser = null;
        }        
   }    
#endif

   public void addExtendsType(ObjectType type) {extendsList.add(type);}
   public void addImplementsType(ObjectType type) {implementsList.add(type);}

   public boolean isMarkedFinal() {
      if (firstChildOfType(FINAL)!=null) return true;
      Modifiers mods = firstChildOfType(Modifiers.class);
      return mods != null && mods.firstChildOfType(FINAL) != null;
   }

   public boolean isMarkedAbstract() {
      if (firstChildOfType(ABSTRACT)!=null) return true;
      Modifiers mods = firstChildOfType(Modifiers.class);
      return mods != null && mods.firstChildOfType(ABSTRACT) != null;
   }

   public boolean isMarkedInterface() {
      return firstChildOfType(INTERFACE) != null;
   }

   public boolean isMarkedClass() {
      return firstChildOfType(CLASS) != null;
   }

   public boolean isSealed() {
      if (firstChildOfType(SEALED)!=null) return true;
      Modifiers mods = firstChildOfType(Modifiers.class);
      return mods != null && mods.firstChildOfType(SEALED) != null;
   }
   
   public boolean isNonSealed() {
      if (firstChildOfType(NON_SEALED)!=null) return true;
      Modifiers mods = firstChildOfType(Modifiers.class);
      return mods != null && mods.firstChildOfType(NON_SEALED) != null;
   }

   public PermitsList getPermitsList() {
      return firstChildOfType(PermitsList.class);
   }

   @Property String name;
}

CodeInjection2 :
{
        CompilationUnit jcu;
}
        ACTIVATE_TOKENS _INJECT (<_INJECT>)
        ":" =>|| "{"
        jcu=CompilationUnit
       "}"
        {
                if (enterIncludes) {
                    grammar.addCodeInjection(jcu);
                }
        }
;

Options# :
    {HashMap<String, Object> settings = new HashMap<>();} 
    Setting(settings) =>||
    (Setting(settings))*
    {grammar.setSettings(settings);}
;

Setting(Map<String,Object> settings) #Setting :
{
      String key;
      Token name;
      Object value = Boolean.TRUE;
}
  ( 
     name = <IDENTIFIER> 
     | 
     name = <_IGNORE_CASE>
     |
     name = <_DEACTIVATE_TOKENS>
  )
  =>|+1
  {
      key = name.getSource().toUpperCase();
  }
  [
     "="
     (
        "true" {value=true;}
        |
        "false" {value=false;}
        |
        <INTEGER_LITERAL> {value = ((IntegerLiteral) lastConsumedToken).getValue();}
        |
        (<STRING_LITERAL>|<TEXT_BLOCK_LITERAL>) {value = ((StringLiteral) lastConsumedToken).getString();}
        |
        SCAN <IDENTIFIER> "."
        =>Name {value = peekNode().toString();}
        |
        <IDENTIFIER> {value = lastConsumedToken.toString();}
        [ <HASH> <IDENTIFIER> { value += "#" + lastConsumedToken.toString();} ]
        ("," {value+=",";}
            <IDENTIFIER> {value+=lastConsumedToken.toString();}
            [ <HASH> <IDENTIFIER> { value += "#" + lastConsumedToken.toString();} ]
        )* 
     )
  ]
  ";"
  {
      settings.put(key, value);
  }
;

BNFProduction #org.congocc.core.BNFProduction :
{
    TreeBuildingAnnotation tba = null;
    Token firstToken=getToken(1), id;
    Expansion exp;
}
    [
        "public" | "private" | "protected"
    ]
    [
       SCAN ReturnType <IDENTIFIER> => ReturnType
       |
       "#" {CURRENT_NODE.setImplicitReturnType(true);}
    ]
    id=<IDENTIFIER> {CURRENT_NODE.setName(id.toString());}
    [FormalParameters]
    [
      ThrowsList
    ]
    [
        tba=TreeNodeDescriptor 
        {
            String nodeName = tba.getNodeName();
            if (nodeName == null) nodeName = CURRENT_NODE.getNodeName();
            grammar.addNodeType(CURRENT_NODE.getName(), nodeName);
        }
    ]
    [
        "RECOVER_TO" ExpansionChoice
        {CURRENT_NODE.setRecoveryExpansion((Expansion)peekNode());} 
    ]
    ":"
    [
        SCAN 2 => <IDENTIFIER> 
        {CURRENT_NODE.setLexicalState(lastConsumedToken.toString());}
        ":"
    ]
    [
        Block 
        {CodeBlock block = (CodeBlock) peekNode();}
        ["#" {block.setAppliesInLookahead(true);}]
        ASSERT ~(";") =>||
    ]
    ExpansionChoice 
    {CURRENT_NODE.setExpansion((Expansion) peekNode());} 
    ";"
    {
        CURRENT_NODE.adjustFirstToken(firstToken);
        if (tba == null && !grammar.getAppSettings().getNodeDefaultVoid()) {
           grammar.addNodeType(CURRENT_NODE.getName(),CURRENT_NODE.getName());
        }
     }
;

TreeNodeDescriptor #TreeBuildingAnnotation :
  "#" (Name|"abstract"|"interface"|"void"|{})
  [
       "("
          [
            (">" | ">=" | "<" | "<=" | "+" | "-")
            {CURRENT_NODE.setInitialShorthand(lastConsumedToken.toString());}  
          ]
          Expression {CURRENT_NODE.setCondition((Expression) peekNode());}
       ")"
  ]
;

InlineTreeNodeDescriptor #TreeBuildingAnnotation :
  [ 
      <BACKSLASH>
    |
      [ "@" {CURRENT_NODE.setLhsProperty(true);} ] Name {CURRENT_NODE.setLHS((Name)peekNode());} "=" 
      =>||
  ]
  <HASH> =>|| 
  Name  
  (
    SCAN ~("(") => {}
    |
    "(" (">" | ">=" | "<" | "<=" | "+" | "-") =>||
    {CURRENT_NODE.setInitialShorthand(lastConsumedToken.toString());}
    [Expression {CURRENT_NODE.setCondition((Expression) peekNode());}] 
    ")"
    |
    "("
    ASSERT ~(ExpansionSequence "|") //A bit kludgy, but we treat this case specially for principle of least surprise.
    Expression {CURRENT_NODE.setCondition((Expression) peekNode());}
    ")"
    // If any of the following tokens are after the closing parenthesesis, this must
    // be an expansion (or the code is just invalid)  
    ASSERT ~(<STAR>|<PLUS>|<HOOK>|<HASH>) 
    =>||
    |
    SCAN "(" ExpansionChoice ")" => {}
    |
    "(" FAIL "Expecting either an expression or an expansion here."
 )
;

INJECT TreeBuildingAnnotation :
{
    @Property String initialShorthand;
    @Property Expression condition;
    @Property Name LHS;
    @Property boolean lhsProperty = false;
    /**
     * Just returns whatever comes after the hash ("#") including "void", etc.
     */
    public String getNodeName() {
        Token hash = (Token) firstChildOfType(HASH);
        if (hash == null) return null;
        Node nextNode = hash.nextSibling();
        if (nextNode instanceof Name) {
            return nextNode.toString();
        }
        Token nextToken = hash.getNext();
        TokenType nextType = nextToken.getType();
        if (nextType != ABSTRACT 
            && nextType != INTERFACE 
            && nextType != VOID) return null;
        return nextToken.toString();
    }

    public boolean isNeverInstantiated() {
        return isVoid() || isAbstract() || isInterface()
        || getGrammar().nodeIsInterface(getNodeName())
        || getGrammar().nodeIsAbstract(getNodeName());
    }
    
    public boolean getGtNode() {
         return initialShorthand !=null;
    }

    public boolean isAbstract() {
        return "abstract".equals(getNodeName());
    }

    public boolean isInterface() {
        return "interface".equals(getNodeName());
    }
    
    public boolean isVoid() {
        return "void".equals(getNodeName());
    }

    public boolean isFullyQualified() {
        String nodeName = getNodeName();
        return nodeName != null && nodeName.indexOf('.') >0;
    }
}


ExpansionChoice :
  ExpansionSequence ( "|" ExpansionSequence)*
;

INJECT ExpansionChoice :
   import org.congocc.core.*;
   import java.util.Set;
   extends Expansion
{
    public java.util.List<ExpansionSequence> getChoices() {
        return childrenOfType(ExpansionSequence.class);
    }
    
    @Override
    public TokenSet getFirstSet() {
         if (firstSet == null) {
            firstSet = new TokenSet(getGrammar());
            for (ExpansionSequence choice : childrenOfType(ExpansionSequence.class)) {
                //firstSet.or(choice.getLookaheadExpansion().getFirstSet());
                firstSet.or(choice.getFirstSet());
            }
         }
         return firstSet;
    }
    
    @Override
    public TokenSet getFinalSet() {
        TokenSet finalSet = new TokenSet(getGrammar());
        for (ExpansionSequence choice : childrenOfType(ExpansionSequence.class)) {
            finalSet.or(choice.getFinalSet());
        }
        return finalSet;
    }
    
    @Override
    protected int getMinimumSize(Set<String> usedNonTerminals) {
        int result = Integer.MAX_VALUE;
        for (ExpansionSequence choice : getChoices()) {
            if (choice.isFailure()) continue; // REVISIT
            int choiceMin = choice.getMinimumSize(usedNonTerminals);
            if (choiceMin ==0) return 0;
            result = Math.min(result, choiceMin);
        }
        return result;
    }
 
    @Override
    protected int getMaximumSize(Set<String> usedNonTerminals) {
        int result = 0;
        for (ExpansionSequence exp : getChoices()) {
            result = Math.max(result, exp.getMaximumSize(usedNonTerminals));
            if (result == Integer.MAX_VALUE) break;
        }
        return result;
    }
    
    @Override
    public boolean potentiallyStartsWith(String productionName, java.util.Set<String> alreadyVisited) {
        for (ExpansionSequence seq : getChoices()) {
            if (seq.potentiallyStartsWith(productionName, alreadyVisited)) return true;
            if (seq.isEnteredUnconditionally()) break;
        }
        return false;
    }

    @Override
    public boolean isSingleTokenLookahead() {
        if (!super.isSingleTokenLookahead()) return false;
        for (ExpansionSequence exp : childrenOfType(ExpansionSequence.class)) {
            if (!exp.isSingleTokenLookahead()) return false;
        }
        return true;
    }
    
    @Override
    public boolean startsWithLexicalChange() {
        return getChoices().stream().anyMatch(ExpansionSequence::startsWithLexicalChange);
    }    
}


ExpansionWithParentheses :
{
    Token lparen = null;
    LexicalStateSwitch lss=null;
    Name LHS = null;
    Token atPrefix = null;
}
   [lss=LexicalStateSwitch | TokenActivation]
   [
       [ atPrefix = "@" ] 
       LHS = Name "=" 
       =>||
   ]
   lparen ="(" =>|| ExpansionChoice {Expansion nested = (Expansion) peekNode();} ")"
   [
       "*" {CURRENT_NODE = new ZeroOrMore();}
       |
       "?" {CURRENT_NODE = new ZeroOrOne();}
       |
       "+" {CURRENT_NODE = new OneOrMore();}
   ]
   {
        CURRENT_NODE.setLHS(LHS);
        CURRENT_NODE.setLhsProperty(atPrefix != null);
   }
   [
       SCAN ~\...\Lookahead => 
       "!" 
       {
           if (CURRENT_NODE instanceof ZeroOrOne) {
               nested.setTolerantParsing(true);
           } else {
               CURRENT_NODE.setTolerantParsing(true);
           }
       }
   ]
   [UpToHere(CURRENT_NODE)]
   {
       Node startNode = lss != null ? lss : lparen;
       CURRENT_NODE.copyLocationInfo(startNode, lastConsumedToken);
   }
;


INJECT ExpansionWithParentheses : 
   import org.congocc.core.*; 
   import org.congocc.core.ExpansionSequence.*;
   extends ExpansionWithNested
   implements SyntaxElement
{
    @Property Name LHS;
    @Property boolean lhsProperty;
    
    @Override 
    public String getSpecifiedLexicalState() {
        LexicalStateSwitch lss = firstChildOfType(LexicalStateSwitch.class);
        return lss == null ? super.getSpecifiedLexicalState() : lss.getLexicalStateName();
    }

    @Override 
    public boolean startsWithLexicalChange() {
        return firstChildOfType(LexicalStateSwitch.class) != null || firstChildOfType(TokenActivation.class) != null
              || getNestedExpansion().startsWithLexicalChange();
    }

    @Override 
    public boolean isSingleTokenLookahead() {
         return super.isSingleTokenLookahead() && getNestedExpansion().isSingleTokenLookahead();
    }
}

ExpansionSequence #org.congocc.core.ExpansionSequence :
{
   Expansion sub;
   Lookahead la = null;
}
  [ 
    SCAN ~\...\Lookahead 
    =>
    la=Lookahead  =>||
    {
       la.setExpansion(CURRENT_NODE);
       CURRENT_NODE.setLookahead(la);
     }
  ]
  (
     ExpansionUnit
  )+!
;

INJECT Assertion :
   import org.congocc.core.Expansion;
   extends org.congocc.core.EmptyExpansion 
{
    @Property Expression assertionExpression, messageExpression;
    @Property Expansion expansion;
    @Property boolean expansionNegated, semanticLookaheadNested;


    @Override 
    public boolean startsWithGlobalCodeAction() {
        return expansion != null || semanticLookaheadNested;
    }
}

Assertion :
   "ASSERT"
   (
    "{" 
       Expression 
       {CURRENT_NODE.setAssertionExpression((Expression) peekNode());}
    "}"
    ["#" {CURRENT_NODE.setSemanticLookaheadNested(true);}]
    |
    ["~" {CURRENT_NODE.setExpansionNegated(true);}] 
    "(" 
    ExpansionChoice {CURRENT_NODE.setExpansion((Expansion) peekNode());}
    ")"
   )
   [
       ":" Expression {CURRENT_NODE.setMessageExpression((Expression)peekNode());}
       [":"]
   ]
   [UpToHere(CURRENT_NODE)]
;

Lookahead# : 
{
   Token amountToken=null;
   boolean hasSemanticLookahead = false, hasExplicitNumericalLookahead=false;
   Expansion expansion = null;
   Expression exp=null;
   Name name = null;
   Node lb = null;
}
[name=Name "=" =>|| {CURRENT_NODE.setLHS(name);}]
<_SCAN>
[
    <INTEGER_LITERAL> {hasExplicitNumericalLookahead = true;}
]
[
    "{" 
    exp=Expression {hasSemanticLookahead = true; CURRENT_NODE.setSemanticLookahead(exp);}
    "}"
    ["#" {CURRENT_NODE.setSemanticLookaheadNested(true);}]
]
[LookBehind =>|| {lb = peekNode();}]
[
    SCAN {!hasExplicitNumericalLookahead} => 
    ["~" {CURRENT_NODE.setNegated(true);}] 
    ExpansionChoice {expansion = (Expansion) peekNode();}
    <RIGHT_ARROW> =>||
    {
       CURRENT_NODE.setNestedExpansion(expansion);
    }
]
(
    SCAN {expansion == null} => <RIGHT_ARROW>
    |
    SCAN {expansion != null || (exp ==null && lb == null)} => {}
)
;

INJECT Lookahead :
    import org.congocc.core.Expansion;
{
    @Property Name LHS;
    @Property Expansion expansion, nestedExpansion;
    @Property boolean negated, semanticLookaheadNested;
    @Property Expression semanticLookahead;

    public boolean getRequiresScanAhead() {
        if (!getLookaheadExpansion().isPossiblyEmpty()) return true;
        if (getSemanticLookahead() != null) return true;
        if (this.getLookBehind()!=null) return true;
        return getAmount() >0;
    }

    public boolean hasSemanticLookahead() {
        return getSemanticLookahead() != null;
    }
    
    public Expansion getLookaheadExpansion() {
        Expansion result = getNestedExpansion();
        if (result != null) {
            return result;
        }
        return expansion;
    }

    public boolean getHasExplicitNumericalAmount() {
        return firstChildOfType(TokenType.INTEGER_LITERAL) != null;
    }

    public int getAmount() {
        IntegerLiteral it = firstChildOfType(IntegerLiteral.class);
        if (it!=null) return it.getValue();
        if (nestedExpansion !=null || expansion.getHasScanLimit()) return Integer.MAX_VALUE;
        return 1;
    }

    public LookBehind getLookBehind() {
        return firstChildOfType(LookBehind.class);
    }    
}

LookBehind : 
   [<TILDE> {CURRENT_NODE.setNegated(true);}] 
   (LookBehindForward | LookBehindBackward)
;

LookBehindForward #void :
   (
       <SLASH>
       (
         ([<TILDE>]<IDENTIFIER>)
         |
         (<DOT>|<VAR_ARGS>)
       )
   )+
   [<BACKSLASH>]
;

LookBehindBackward #void :
   (
       <BACKSLASH>
       (
          ([<TILDE>]<IDENTIFIER>)
          |
          (<DOT>|<VAR_ARGS>)
       )
   )+
   [<SLASH>]
;

INJECT LookBehind :
import java.util.*;
{
    @Property boolean negated;

    public boolean isBackward() {
        return getChild(0) instanceof Backslash || getChild(1) instanceof Backslash;
    }

    public boolean getHasFinalEllipsis() {
        Token t = (Token) getChild(getChildCount() -1);
        return t.toString().equals("...");
    }

    public List<String> getPath() {
        ArrayList<String> result = new ArrayList<>();
        boolean negated = false;
        for (Token t : childrenOfType(Token.class)) {
            String img = t.toString();
            if (img.charAt(0) == '\\' || img.charAt(0)=='/') {
                negated = false;
                continue;
            } 
            if (img.equals("~")) {
                negated = true;
                continue;
            }
            if (negated) {
                result.add("~" + img);
            } else {
               result.add(img);
            }
            negated = false;
        }
        if (result.get(0).equals("~")) {
            result.remove(0);
        }
        return result;
    }

    public boolean getHasEndingSlash() {
        Token lastToken = (Token) getChild(getChildCount()-1);
        String img = lastToken.toString();
        return img.equals("\\") || img.equals("/");
    }

    private String routineName;
    
    public String getRoutineName() {
        if (routineName == null) {
            String prefix = getAppSettings().generateIdentifierPrefix("backscan");
            routineName = getAppSettings().generateUniqueIdentifier(prefix, this);
        }
        return routineName;
    }
}


ChildNameInfo(Expansion expansion) : //#void :
{
    String name;
    boolean multiple = false;
}
  // TODO these delimiters are provisional - agreement needed on final form
  "/"
  (
    <IDENTIFIER> { name = ((Token) peekNode()).toString(); }
    |
    ( "["
      <IDENTIFIER> { name = ((Token) peekNode()).toString(); multiple = true; }
    "]" )
  )
  "/"
  {
    expansion.setChildName(name);
    expansion.setMultipleChildren(multiple);
  }
;

ExpansionUnit #void :
 (
  UncacheTokens
  |
  Failure
  |
  Block {CodeBlock block = (CodeBlock) peekNode();}
  [
    "#" 
    {
        block.setAppliesInLookahead(true);
        popNode();
    }
  ]
  |
  UnparsedCodeBlock // Currently unused
  |
  SCAN 1 ~\...\Lookahead => AttemptBlock
  |
  SCAN 1 ~\...\Lookahead => TryBlock
  |
  Assertion
  |
  ExpansionWithParentheses 
  |
  ZeroOrOne 
  |
  Terminal 
  |
  NonTerminal
  |
  FAIL
 )
 {Expansion result = (Expansion) peekNode();}
 [
    SCAN ~\...\Lookahead => 
    InlineTreeNodeDescriptor =>||
    { result.setTreeNodeBehavior((TreeBuildingAnnotation) peekNode()); }
 ]
;

#NonTerminal #org.congocc.core.NonTerminal :
  [
    ["@" {CURRENT_NODE.setLhsProperty(true);} ] 
    Name {CURRENT_NODE.setLHS((Name)peekNode());} "=" 
    =>||
  ]
  <IDENTIFIER>
  =>||
  [
    SCAN "(" ExpansionSequence "|" => {}
    |
    SCAN "(" ExpansionChoice ")" ("*"|"+"|"?") => {}
    |
    InvocationArguments =>||
  ]
  [
     SCAN ~\...\Lookahead =>
     "!"
     {CURRENT_NODE.setTolerantParsing(true);}
  ]
  [ChildNameInfo(CURRENT_NODE)] 
  [UpToHere(CURRENT_NODE)]
  {return CURRENT_NODE;}
;

Terminal# :
  SCAN ["@"] [Name "="] (<STRING_LITERAL>|<CHARACTER_LITERAL>|<SINGLE_QUOTE_STRING>|"<")
  =>
  [
    SCAN ~\...\Lookahead ["@"] Name "=" =>
    ["@" {CURRENT_NODE.setLhsProperty(true);} ]
    Name {CURRENT_NODE.setLHS((Name) peekNode());}
    "="
  ]
  ACTIVATE_TOKENS _EOF(RegexpStringLiteral | RegexpRef | EndOfFile ) 
  {
      RegularExpression result = (RegularExpression) peekNode();
      if (result instanceof RegexpStringLiteral) {
            ((RegexpStringLiteral) result).setLexicalState(grammar.getDefaultLexicalState());
      }
      CURRENT_NODE.setRegexp(result);
      CURRENT_NODE.setLabel(result.getLabel());
  }
  [
      SCAN ~\...\Lookahead
      => "!"
      {
          CURRENT_NODE.setTolerantParsing(true);
      }
  ]
  [
      ChildNameInfo(CURRENT_NODE)
  ] 
  [
    UpToHere(CURRENT_NODE)
  ]
;

INJECT Terminal :
   import org.congocc.core.*;
   import org.congocc.core.ExpansionSequence.*;
   import java.util.Set;
   extends Expansion
   implements SyntaxElement
{
    @Property RegularExpression regexp;
    @Property Name LHS;
    @Property boolean lhsProperty;
    @Property String label;

    public int getOrdinal() {
        return regexp.getOrdinal();
    }

    public int getMinimumSize(Set<String> unused) {return 1;}

    public int getMaximumSize(Set<String> unused) {return 1;}

    public TokenSet getFirstSet() {
        if (firstSet == null) {
            firstSet = new TokenSet(getGrammar());
            firstSet.set(getOrdinal());
        }
        return firstSet;
    }

    public TokenSet getFinalSet() {return getFirstSet();}
}   

UpToHere(Expansion exp) #void :
   <UP_TO_HERE>
   {
       String img = lastConsumedToken.toString();
       exp.setScanLimit(true);
       int lastChar = img.codePointBefore(img.length());
       if (Character.isDigit(lastChar)) {
           exp.setScanLimitPlus(lastChar - '0');
       }
   }
;

//The following two productions are not actually used. These constructs are now 
// handled by ExpansionWithParentheses so the following two productions
// are not actually used. They have to be there so that the ZeroOrMore and
// OneOrMore types get defined. REVISIT. Need a way of defining Node subtypes
// without creating a dummy grammar rule for them.
ZeroOrMore : "(" ExpansionChoice ")" "*";
OneOrMore : "(" ExpansionChoice ")" "+"; 

//This production just matches the square bracket syntax. 
// The (...)? syntax is handled by ExpansionWithParentheses
ZeroOrOne : 
    [LexicalStateSwitch | TokenActivation]
    [
        ["@" {CURRENT_NODE.setLhsProperty(true);} ] 
        Name {CURRENT_NODE.setLHS((Name)peekNode());} "=" 
        =>||
    ]
    "[" =>|| ExpansionChoice {Expansion exp = (Expansion) peekNode();} "]"
     ["!" {exp.setTolerantParsing(true);}]
     [UpToHere(CURRENT_NODE)]
;

INJECT ZeroOrOne : 
     import org.congocc.core.Expansion;
     import org.congocc.core.TokenSet;
     extends ExpansionWithParentheses 
{
    @Override
    protected int getMinimumSize(java.util.Set<String> unused) {return 0;}
}


INJECT ZeroOrMore : 
     import org.congocc.core.Expansion;
     import org.congocc.core.TokenSet;
     import java.util.Set;
     extends ExpansionWithParentheses 
{
    @Override  
    protected int getMinimumSize(Set<String> unused) {return 0;}
    
    @Override
    protected int getMaximumSize(Set<String> unused) {return Integer.MAX_VALUE;}
}


INJECT OneOrMore : 
     import org.congocc.core.Expansion;
     import org.congocc.core.TokenSet;
     extends ExpansionWithParentheses 
{
    @Override 
    protected int getMaximumSize(java.util.Set<String> unused) {return Integer.MAX_VALUE;}
}


AttemptBlock : 
 "ATTEMPT" ExpansionChoice "RECOVER"  (ExpansionWithParentheses | Block)
;

INJECT AttemptBlock : 
   import java.util.List;
   import org.congocc.core.Expansion;
   import org.congocc.core.TokenSet;
   extends org.congocc.core.ExpansionWithNested;
{
    public Expansion getRecoveryExpansion() {
       return (Expansion) getChild(3);
    }
}

UncacheTokens# : "UNCACHE_TOKENS" ;   

INJECT UncacheTokens : extends org.congocc.core.EmptyExpansion;

Failure# : 
   {
       Expression exp = null;
   }
   "FAIL"
   [
      [":"]
      exp=Expression 
      |
      Block
   ]
   {
       CURRENT_NODE.setExp(exp);
   }
;

INJECT Failure :
   extends org.congocc.core.EmptyExpansion
{
    @Property Expression exp;
    
    public CodeBlock getCode() {
        return firstChildOfType(CodeBlock.class);
    }
}

LexicalStateSwitch : "LEXICAL_STATE" <IDENTIFIER> ;

INJECT LexicalStateSwitch : {
   public String getLexicalStateName() {
       return firstChildOfType(Identifier.class).toString();
   }
}

TokenActivation : 
   ("ACTIVE_TOKENS" | "ACTIVATE_TOKENS" | "DEACTIVATE_TOKENS" {CURRENT_NODE.setDeactivate(true);})
   ["+"|"-"] <IDENTIFIER>
   ([","] ["+"|"-"] <IDENTIFIER>)*
;

INJECT TokenActivation : 
   import java.util.List;
   import java.util.ArrayList;
{
    @Property boolean deactivate;
    public List<String> getTokenNames() {
        List<String> result = new ArrayList<>();
        for (Identifier id : childrenOfType(Identifier.class)) {
            result.add(id.toString());
        }
        return result;
    }

    public List<String> getDeactivatedTokens() {
        List<String> result = new ArrayList<>();
        for (Identifier id : childrenOfType(Identifier.class)) {
            if (id.getPrevious().getType() == MINUS) {
                result.add(id.toString());
            }
            else if (isDeactivate() && id.getPrevious().getType() != PLUS) {
                result.add(id.toString());
            }
        }
        return result;
    }

    public List<String> getActivatedTokens() {
        List<String> result = new ArrayList<>();
        for (Identifier id : childrenOfType(Identifier.class)) {
            if (id.getPrevious().getType() == PLUS) {
                result.add(id.toString());
            }
            else if (!isDeactivate() && id.getPrevious().getType() != MINUS) {
                result.add(id.toString());
            }
        }
        return result;
    }
}


TryBlock : 
    "try" "{" ExpansionChoice "}"
    (
        CatchBlock
    )*
    [
        FinallyBlock
    ]
;


INJECT TryBlock  : 
    extends org.congocc.core.ExpansionWithNested;
{
    public java.util.List<CatchBlock> getCatchBlocks() {
        return childrenOfType(CatchBlock.class);
    }

    public FinallyBlock getFinallyBlock() {
        return firstChildOfType(FinallyBlock.class);
    }
    
}


